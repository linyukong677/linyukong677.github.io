---
layout: post
title: Monte Carlo
date: 2022-11-06 17:13 +0800
last_modified_at: 2022-11-07 19:08 +0800
tags: [Machine Learning, Bayesian]
toc:  true
math: true
---

书读百遍，其义自见。
{: .message }

## Monte Carlo 方法引入

wiki上解释是：蒙特卡罗方法（英语：Monte Carlo method），也称统计模拟方法，是一种以**概率统计理论**为指导的**数值计算方法**。从定义上看，Monte Carlo方法本身所关注的，是数值计算求解问题。事实上最早的蒙特卡罗方法都是为了求解一些不太好求解的求和或者积分问题。比如对于下面积分：

$$
\theta=\int\limits_{a}^{b}f(x)dx
$$

如果我们求不出$$f(x)$$积分回去对应的原函数，那么$$\theta$$很难求解。但是Monte Carlo思想为我们提供了一种求$$\theta$$近似解的方法。我们在区间$$[a,b]$$上随机采样n个点，记为$$x_1,x_2,\cdots,x_n$$，然后计算对应的函数值$$f(x_1),f(x_2),\cdots,f(x_n)$$。我们得到的近似解为：

$$
\theta\approx\frac{b-a}{n}\sum\limits_{i=1}^{n}f(x_i)
$$

如果你能理解这个近似解的合理性，那么恭喜你，你已经掌握了基本的Monte Carlo思想。

## 概率分布采样

我之所以说上面的例子只是基本的Monte Carlo思想，是因为在积分的这个特殊语境下，x在区间$$[a,b]$$上的采样是均匀随机的（$$x\sim Uniform(a,b)$$），你可以理解这种均匀随机并不总是被保证的。此时，假设$$x\sim p(x)$$，我们需要从概率分布$$p(x)$$中采样，这个过程就是概率分布采样。回到上面的例子，我们根据$$x$$所服从的分布$$p(x)$$采样n个点$$x_1,x_2,\cdots,x_n$$，我们的近似解变成：

$$
\theta=\int\limits_{a}^{b}f(x)dx=\int\limits_{a}^{b}\frac{f(x)}{p(x)}p(x)dx\approx\frac{1}{n}\sum\limits_{i=1}^{n}\frac{f(x_i)}{p(x_i)}
$$

但是，我们如何从概率分布$$p(x)$$中采样呢？唔，这是个麻烦的问题。概率论的知识告诉我们，均匀分布$$Uniform(0,1)$$是非常容易采样样本的，而其他的常见分布的采样都可以借助$$Uniform(0,1)$$上的采样经过变换得到，我们称这种技术为**采样变换**。

那么，更加复杂的，不常见的分布怎么办呢（实际问题中更多的是不常见分布），我们介绍一种技术叫做**接受-拒绝采样**。具体的采样过程如下：

![拒绝接受采样.png](https://s2.loli.net/2022/11/06/zlEAfSwBYD2OV35.png)

对于实际的不常见分布$$p(z)$$，我们设定一个常见分布$$kq(z)$$，$$k$$为常数保证$$kq(z)\geq p(z)$$。首先，采样得到$$q(x)$$的一个样本$$z_1$$。然后，从均匀分布$$(0,kq(z0))$$中采样得到一个值$$u$$。如果$$u$$落在了上图中的灰色区域$$(p(z_1),kq(z_1)]$$，则拒绝这次抽样，否则接受这个样本$$z0$$。重复以上过程得到n个接受的样本$$z_1,z_2,...z_n$$，然后按之前的方法求解。

